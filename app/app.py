# app.py (v1.1 - å¢åŠ äº†æµå¼æ›´æ–°åŠŸèƒ½)

import streamlit as st
import pandas as pd
from datetime import date, timedelta

# ä»æˆ‘ä»¬çš„æ•°æ®å¤„ç†æ¨¡å—ä¸­å¯¼å…¥æ‰€æœ‰éœ€è¦çš„å‡½æ•°
import data_handler as dh

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Aè‚¡å¹¶è´­äº‹ä»¶è¿½è¸ªå™¨",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

st.title('ğŸ“ˆ Aè‚¡å¹¶è´­äº‹ä»¶è¿½è¸ªå™¨ (ä¸“ä¸šç‰ˆ)')
st.markdown("æ•°æ®æ¥æº: å·¨æ½®èµ„è®¯ç½‘ | è´¢åŠ¡æ•°æ®: AkShare")

# --- æ–°å¢ï¼šä¸€ä¸ªä¸“é—¨ç”¨äºæ¸²æŸ“ç»“æœçš„å‡½æ•° ---
def display_results(df):
    """ä¼ å…¥ä¸€ä¸ªDataFrameï¼Œå°†å…¶å†…å®¹ä»¥st.expanderçš„å½¢å¼å±•ç¤ºå‡ºæ¥"""
    st.info(f"å·²å®æ—¶åŠ è½½ {len(df)} æ¡ç»“æœã€‚ç‚¹å‡»æ¯æ¡ç»“æœå‰çš„ `>` ç¬¦å·å¯å±•å¼€æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ã€‚")
    st.warning("AIè‡ªåŠ¨æå–çš„â€œæ‹Ÿå¹¶è´­å…¬å¸â€å’Œâ€œäº¤æ˜“å¯¹ä»·â€ç­‰ä¿¡æ¯å¯èƒ½ä¸å‡†ç¡®ï¼Œè¯·åŠ¡å¿…ç‚¹å‡»å…¬å‘Šé“¾æ¥è¿›è¡Œæ ¸å®ã€‚")

    for index, row in df.iterrows():
        summary_title = f"**{row['å…¬å¸åç§°']} ({row['è‚¡ç¥¨ä»£ç ']})** | {row['å…¬å‘Šæ—¥æœŸ']}"
        with st.expander(summary_title):
            st.markdown(f"**å…¬å‘Šæ ‡é¢˜**: {row['å…¬å‘Šæ ‡é¢˜']}")
            st.markdown(f"**å…¬å‘Šé“¾æ¥**: [ç‚¹å‡»æŸ¥çœ‹åŸæ–‡]({row['PDFé“¾æ¥']})")
            st.markdown("---")
            
            st.subheader("äº¤æ˜“æ ¸å¿ƒæ¦‚è¦ (AIæå–)")
            col1, col2, col3 = st.columns(3)
            col1.metric("æ‹Ÿå¹¶è´­å…¬å¸åç§°", row.get('æ‹Ÿå¹¶è´­å…¬å¸åç§°', 'N/A'))
            col2.metric("äº¤æ˜“å¯¹ä»·", row.get('äº¤æ˜“å¯¹ä»·', 'N/A'))
            col3.text_area("æ¶‰åŠäº¤æ˜“è‚¡ä¸œ", row.get('æ¶‰åŠäº¤æ˜“è‚¡ä¸œ', 'N/A'), height=100, disabled=True)
            
            st.markdown("---")

            st.subheader("ä¸Šå¸‚å…¬å¸å¿«ç…§")
            col_a, col_b, col_c = st.columns(3)
            col_a.metric("æ€»å¸‚å€¼ (äº¿å…ƒ)", f"{row.get('æ€»å¸‚å€¼', 0) / 1e8:.2f}" if pd.notna(row.get('æ€»å¸‚å€¼')) else "N/A")
            col_b.metric("å¸‚ç›ˆç‡ (åŠ¨æ€)", f"{row.get('å¸‚ç›ˆç‡-åŠ¨æ€'):.2f}" if pd.notna(row.get('å¸‚ç›ˆç‡-åŠ¨æ€')) else "N/A")
            col_c.metric("èµ„äº§è´Ÿå€ºç‡ (%)", f"{row.get('èµ„äº§è´Ÿå€ºç‡(%)'):.2f}" if pd.notna(row.get('èµ„äº§è´Ÿå€ºç‡(%)')) else "N/A")
            
            st.text_area("è¡Œä¸šé¢˜æ", row.get('è¡Œä¸šé¢˜æ', 'N/A'), height=100, disabled=True)


# --- 2. åº”ç”¨ç•Œé¢å¸ƒå±€ ---
with st.sidebar:
    st.header("ğŸ” ç­›é€‰æ¡ä»¶")
    today = date.today()
    default_start_date = today - timedelta(days=90)
    date_range = st.date_input(
        "é€‰æ‹©å…¬å‘Šæ—¥æœŸèŒƒå›´",
        value=(default_start_date, today),
        min_value=date(2010, 1, 1),
        max_value=today,
        format="YYYY-MM-DD"
    )
    st.info("æ¨èä½¿ç”¨ç²¾å‡†å…³é”®è¯ä»¥é¿å…æ— å…³å†…å®¹ã€‚")
    keywords_input = st.text_area(
        "è¾“å…¥æœç´¢å…³é”®è¯ (æ¯è¡Œä¸€ä¸ª)",
        "é‡å¤§èµ„äº§é‡ç»„é¢„æ¡ˆ\né‡å¤§èµ„äº§é‡ç»„è‰æ¡ˆ\nå‘è¡Œè‚¡ä»½è´­ä¹°èµ„äº§é¢„æ¡ˆ\nå‘è¡Œè‚¡ä»½è´­ä¹°èµ„äº§è‰æ¡ˆ"
    )
    keywords = [k.strip() for k in keywords_input.split('\n') if k.strip()]

# --- 3. ä¸»ç¨‹åºé€»è¾‘ ---

# å…³é”®æ”¹åŠ¨(1): åœ¨ä¸»é¡µé¢åˆ›å»ºä¸€ä¸ªç©ºçš„å ä½ç¬¦
results_placeholder = st.empty()

if st.sidebar.button('ğŸš€ å¼€å§‹æŠ“å–å’Œåˆ†æ'):
    # æ¸…ç©ºä¹‹å‰çš„sessionå’Œå ä½ç¬¦
    st.session_state.pop('final_data', None)
    results_placeholder.empty()

    if not keywords or len(date_range) != 2:
        st.error("è¯·è¾“å…¥å…³é”®è¯å¹¶é€‰æ‹©æœ‰æ•ˆçš„æ—¥æœŸèŒƒå›´ã€‚")
    else:
        start_date, end_date = date_range
        
        # æ•…éšœåˆ‡æ¢é€»è¾‘ä¿æŒä¸å˜
        results_df = pd.DataFrame()
        try:
            with st.spinner('æ­£åœ¨ä»ä¸»æ•°æ®æº(å·¨æ½®èµ„è®¯ç½‘)æŠ“å–å…¬å‘Šåˆ—è¡¨...'):
                results_df = dh.scrape_cninfo(keywords, start_date, end_date)
            if results_df.empty:
                raise ValueError("ä¸»æ•°æ®æºæœªè¿”å›ä»»ä½•æ•°æ®")
        except Exception:
            with results_placeholder.container():
                st.warning("âš ï¸ æ£€æµ‹åˆ°ä¸»æ•°æ®æº(å·¨æ½®)è®¿é—®å¤±è´¥æˆ–æ— ç»“æœï¼Œå·²è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ•°æ®æº(ä¸œæ–¹è´¢å¯Œ)ã€‚")
                st.info("æ­£åœ¨å°è¯•ä»å¤‡ç”¨æ•°æ®æºæŠ“å–...")
            try:
                results_df = dh.scrape_akshare(keywords, start_date, end_date)
            except Exception as e_ak:
                st.error(f"å¤‡ç”¨æ•°æ®æº(AkShare)ä¹ŸæŠ“å–å¤±è´¥: {e_ak}")

        if results_df.empty:
            results_placeholder.warning("åœ¨æŒ‡å®šæ¡ä»¶ä¸‹ï¼Œä¸»ã€å¤‡æ•°æ®æºå‡æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³å…¬å‘Šã€‚")
        else:
            with results_placeholder.container():
                st.success(f"æ‰¾åˆ° {len(results_df)} æ¡ç›¸å…³å…¬å‘Šï¼Œå¼€å§‹é€æ¡æ·±åº¦è§£æ...")
            
            # æ‰¹é‡è·å–è´¢åŠ¡æ•°æ® (è¿™ä¸€æ­¥ä»ç„¶éœ€è¦å…ˆå®Œæˆ)
            with st.spinner('æ­£åœ¨æ‰¹é‡è·å–ä¸Šå¸‚å…¬å¸è´¢åŠ¡æ•°æ®...'):
                all_stock_codes = results_df['è‚¡ç¥¨ä»£ç '].unique().tolist()
                financial_data_df = dh.get_stock_financial_data(all_stock_codes)
            
            if not financial_data_df.empty:
                results_df = pd.merge(results_df, financial_data_df, on='è‚¡ç¥¨ä»£ç ', how='left')

            # å…³é”®æ”¹åŠ¨(2): é€æ¡å¤„ç†å¹¶å®æ—¶æ›´æ–°å ä½ç¬¦
            processed_rows = []
            for index, row in results_df.iterrows():
                details = dh.extract_details_from_pdf(row['PDFé“¾æ¥'])
                row['æ‹Ÿå¹¶è´­å…¬å¸åç§°'], row['äº¤æ˜“å¯¹ä»·'], row['æ¶‰åŠäº¤æ˜“è‚¡ä¸œ'] = details
                processed_rows.append(row)

                # æ¯å¤„ç†å®Œä¸€æ¡ï¼Œå°±ç”¨æœ€æ–°çš„å®Œæ•´ç»“æœåˆ—è¡¨å»æ›´æ–°å ä½ç¬¦çš„å†…å®¹
                with results_placeholder.container():
                    st.success(f"æ‰¾åˆ° {len(results_df)} æ¡å…¬å‘Šï¼Œå·²å®æ—¶è§£æ {len(processed_rows)}/{len(results_df)} æ¡...")
                    current_results_df = pd.DataFrame(processed_rows)
                    display_results(current_results_df) # è°ƒç”¨æˆ‘ä»¬æ–°å¢çš„æ¸²æŸ“å‡½æ•°
            
            # å¾ªç¯ç»“æŸåï¼Œå°†æœ€ç»ˆç»“æœå­˜å…¥session_state
            final_df = pd.DataFrame(processed_rows)
            st.session_state['final_data'] = final_df

# --- 4. å¦‚æœsessionä¸­æœ‰æ•°æ®ï¼Œç›´æ¥å±•ç¤ºæœ€ç»ˆç»“æœ ---
elif 'final_data' in st.session_state:
    final_df = st.session_state['final_data']
    with results_placeholder.container():
        st.success("æ•°æ®åŠ è½½å®Œæˆï¼")
        display_results(final_df)
